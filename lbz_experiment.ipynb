{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### preprocessing\n",
    "- drop NaN values\n",
    "- removed 3rd gender (n=1)\n",
    "- merge rare classes\n",
    "- drop classes with less than 25 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relative imports\n",
    "from uncertainty_aware_diagnosis import ICD10data, SimpleMLP\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# absolute imports\n",
    "import polars as pl\n",
    "import pickle\n",
    "import numpy as np\n",
    "from pycalib.visualisations import plot_reliability_diagram\n",
    "from pycalib.models.calibrators import LogisticCalibration\n",
    "from pycalib.metrics import classwise_ECE, conf_ECE\n",
    "\n",
    "# paths\n",
    "train_csv = \"./data/lbz-train.csv\"\n",
    "val_csv = \"./data/lbz-val.csv\"\n",
    "test_csv = \"./data/lbz-test.csv\"\n",
    "ohe_pkl = \"./data/ohe_cats.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "target = \"icd10_main_code\"\n",
    "categorical = [\n",
    "    \"zorginstellingnaam\",\n",
    "    \"gender\",\n",
    "    \"clinical_specialty\",\n",
    "    \"DBC_specialty_code\",\n",
    "    \"DBC_diagnosis_code\",\n",
    "    \"icd10_subtraject_code\",\n",
    "]\n",
    "numerical = [\"age\"]\n",
    "\n",
    "# get one-hot encoded features of full dataset (all categories)\n",
    "# ohe_df = pl.read_csv(ohe_csv).to_pandas()['ohe_cats']\n",
    "# ohe_cats =[]\n",
    "# for cat in ohe_df:\n",
    "#     ohe_cats.append(cat)\n",
    "\n",
    "with open(ohe_pkl, \"rb\") as f:\n",
    "    ohe_cats = pickle.load(f)\n",
    "\n",
    "train = ICD10data(\n",
    "    csv_path=train_csv,\n",
    "    numerical=numerical,\n",
    "    categorical=categorical,\n",
    "    high_card=[],\n",
    "    target=target,\n",
    "    dropna=True,\n",
    "    use_embedding=False,\n",
    "    ohe_categories=ohe_cats,  # use one-hot encoded categorie of full dataset\n",
    ")\n",
    "val = ICD10data(\n",
    "    csv_path=val_csv,\n",
    "    numerical=numerical,\n",
    "    categorical=categorical,\n",
    "    high_card=[],\n",
    "    target=target,\n",
    "    dropna=True,\n",
    "    use_embedding=False,\n",
    "    ohe_categories=ohe_cats,  # use one-hot encoded categorie of full dataset\n",
    "    encoder=train.encoder,  # use encoder from training set\n",
    "    scaler=train.scaler,  # use scalor from train set\n",
    ")\n",
    "test = ICD10data(\n",
    "    csv_path=test_csv,\n",
    "    numerical=numerical,\n",
    "    categorical=categorical,\n",
    "    high_card=[],\n",
    "    target=target,\n",
    "    dropna=True,\n",
    "    use_embedding=False,\n",
    "    ohe_categories=ohe_cats,  # use one-hot encoded categorie of full dataset\n",
    "    encoder=train.encoder,  # use encoder from training set\n",
    "    scaler=train.scaler,  # use scalor from train set\n",
    ")\n",
    "\n",
    "input_dim = train.X.shape[1]\n",
    "output_dim = train.classes.shape[0]\n",
    "\n",
    "print(f\"Number of icd10 classes: {len(train.classes)}\")\n",
    "print(f\"(input_dim: {input_dim}, output_dim: {output_dim})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables dataloader\n",
    "batch_size = 32\n",
    "shuffle = True\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=shuffle)\n",
    "val_loader = DataLoader(val, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3edbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dummy = ICD10data(\n",
    "    csv_path=train_csv,\n",
    "    numerical=numerical,\n",
    "    categorical=categorical,\n",
    "    high_card=[],\n",
    "    target=target,\n",
    "    dropna=True,\n",
    "    use_embedding=False,\n",
    "    ohe_categories=ohe_cats,\n",
    ")\n",
    "\n",
    "# Select the first 640 rows\n",
    "train_dummy.X = train_dummy.X[:640]\n",
    "train_dummy.y = train_dummy.y[:640]\n",
    "\n",
    "train_dummy_loader = DataLoader(train_dummy, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fb793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a single \"zorginstellingnaam\" from the existing train, val, and test sets\n",
    "selected_zorginstellingnaam = train_dummy.X['zorginstellingnaam'].unique()[0]\n",
    "\n",
    "# Filter the existing datasets\n",
    "train_single_hosp = train[train.X['zorginstellingnaam'] == selected_zorginstellingnaam]\n",
    "val_single_hosp = val[val.X['zorginstellingnaam'] == selected_zorginstellingnaam]\n",
    "test_single_hosp = test[test.X['zorginstellingnaam'] == selected_zorginstellingnaam]\n",
    "\n",
    "# Create DataLoaders for the filtered datasets\n",
    "train_loader_unique = DataLoader(train_single_hosp, batch_size=batch_size, shuffle=shuffle)\n",
    "val_loader_unique = DataLoader(val_single_hosp, batch_size=batch_size, shuffle=shuffle)\n",
    "test_loader_unique = DataLoader(test_single_hosp, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables MLP\n",
    "num_epochs = 25\n",
    "early_stopping_patience = 10\n",
    "learning_rate = 1e-3\n",
    "dropout = 0.2\n",
    "hidden_dim = 256\n",
    "\n",
    "model = SimpleMLP(\n",
    "    input_dim=input_dim, hidden_dim=hidden_dim, num_classes=output_dim, dropout=dropout\n",
    ")\n",
    "model.fit(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    num_epochs=num_epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    early_stopping_patience=early_stopping_patience,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "y_pred = model.predict(test.X)\n",
    "y_proba = model.predict_proba(test.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test.y.numpy()\n",
    "\n",
    "# select y labels: the most common, the most rare, and middle\n",
    "y_select_table = (\n",
    "    pl.DataFrame(train.y.numpy()).to_series().value_counts(sort=True)[0, 500, -1]\n",
    ")\n",
    "y_select = list(y_select_table[\"column_0\"])\n",
    "y_mask = np.isin(y_test, y_select)\n",
    "y_test_select = y_test[y_mask]\n",
    "y_proba_rows_select = y_proba[y_mask]\n",
    "y_proba_select = y_proba_rows_select[:, y_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_reliability_diagram(\n",
    "    y_test_select,\n",
    "    [\n",
    "        y_proba_select,\n",
    "    ],\n",
    "    legend=[\n",
    "        \"MLP\",\n",
    "    ],\n",
    "    class_names=list(test.classes[y_select]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables calibrator\n",
    "C = 0.002\n",
    "solver = \"lbfgs\"\n",
    "\n",
    "# 1) get your raw logits from the MLP\n",
    "props_val = model.predict_proba(val.X)  # shape (n_val, n_classes)\n",
    "probs_test = model.predict_proba(test.X)  # shape (n_test, n_classes)\n",
    "\n",
    "# 2) instantiate & fit the pycalib logistic (Platt) calibrator\n",
    "calibrator = LogisticCalibration(\n",
    "    C=C, solver=solver, multi_class=\"multinomial\", log_transform=True\n",
    ")\n",
    "calibrator.fit(props_val, val.y.numpy())\n",
    "\n",
    "# 3) use it to get calibrated probabilities on your test set\n",
    "probs_calibrated = calibrator.predict_proba(probs_test)  # shape (n_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba_rows_select_test = probs_test[y_mask]\n",
    "y_proba_select_test = y_proba_rows_select_test[:, y_select]\n",
    "y_proba_rows_select_cali = probs_calibrated[y_mask]\n",
    "y_proba_select_cali = y_proba_rows_select_cali[:, y_select]\n",
    "\n",
    "_ = plot_reliability_diagram(\n",
    "    y_test_select,\n",
    "    [y_proba_select_test, y_proba_select_cali],\n",
    "    legend=[\"MLP\", \"+ Calibrator\"],\n",
    "    class_names=list(test.classes[y_select]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in conf_ECE, classwise_ECE:  # ECE,\n",
    "    print(metric.__name__)\n",
    "    print(\"Classifier = {:.3f}\".format(metric(test.y.numpy(), probs_test, bins=15)))\n",
    "    print(\n",
    "        \"Calibrator = {:.3f}\".format(metric(test.y.numpy(), probs_calibrated, bins=15))\n",
    "    )\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c231fc1e",
   "metadata": {},
   "source": [
    "# Temprature scaling\n",
    "Multiclass platt's scaling is more flexible but potentially more data-hungry (one weight + bias per class). temperature scaling is based on a single‐parameter rescaling (Single scalar T that uniformly “softens” or “sharpens” all logits), therefore it might better in the current setting. The drawback is its low flexibility because of the single parameter it can only scale calibration globaly instead of each class seperately. Therefore also lower risk on overfitting. Therefore, it is promising when the network is systematically over- or under-confident across all classes, which is the case. Suitable when in case of a small validation set.\n",
    "Platt's scaling is more suited for class-specific miscallibration (not the case given it is under-confident accross all) and when having plenty of validation data. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc4670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract logits on val & test\n",
    "logits_val = model.predict_logits(val.X)      # shape (n_val, n_classes)\n",
    "logits_test = model.predict_logits(test.X)    # shape (n_test, n_classes)\n",
    "\n",
    "# fit temperature\n",
    "temp_scaler = TemperatureScaling(device=next(model.parameters()).device)\n",
    "temp_scaler.fit(logits_val, val.y.numpy())\n",
    "\n",
    "# get calibrated probabilities\n",
    "probs_calibrated = temp_scaler.predict_proba(logits_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0af6945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare on your selected subset exactly as you did before\n",
    "y_proba_rows_select_test  = probs_test[y_mask]\n",
    "y_proba_select_test      = y_proba_rows_select_test[:, y_select]\n",
    "y_proba_rows_select_cali = probs_calibrated[y_mask]\n",
    "y_proba_select_cali      = y_proba_rows_select_cali[:, y_select]\n",
    "\n",
    "# re-plot reliability\n",
    "_ = plot_reliability_diagram(\n",
    "    y_test_select,\n",
    "    [y_proba_select_test, y_proba_select_cali],\n",
    "    legend=[\"MLP\", \"+ Temp-scale\"],\n",
    "    class_names=list(test.classes[y_select]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec1f486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute ECEs\n",
    "for metric in (conf_ECE, classwise_ECE):\n",
    "    print(metric.__name__)\n",
    "    print(\"Classifier       = {:.3f}\".format(metric(test.y.numpy(), probs_test,       bins=15)))\n",
    "    print(\"Temp-scaled      = {:.3f}\".format(metric(test.y.numpy(), probs_calibrated, bins=15)))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fda658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after fitting temp_scaler as above\n",
    "probs_temp = temp_scaler.predict_proba(logits_test)\n",
    "print(\"Temp‐scaled ECE:\", conf_ECE(test.y.numpy(), probs_temp, bins=15))\n",
    "print(\"Logistic ECE:\",  conf_ECE(test.y.numpy(), probs_calibrated, bins=15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca067d8",
   "metadata": {},
   "source": [
    "# Group common, uncommon and rare classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc5ece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93da1d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Get raw labels & probs\n",
    "# ------------------------------------------------\n",
    "# Assuming your ICD10data objects expose .y as a torch.Tensor\n",
    "y_train = train.y.numpy()       # shape (n_train,)\n",
    "y_test  = test.y.numpy()        # shape (n_test,)\n",
    "probs_test = model.predict_proba(test.X)  # shape (n_test, num_classes)\n",
    "num_classes = probs_test.shape[1]\n",
    "\n",
    "# 2) Compute class frequencies & sorted order\n",
    "# ------------------------------------------------\n",
    "class_counts = np.bincount(y_train, minlength=num_classes)\n",
    "sorted_idxs  = np.argsort(class_counts)[::-1]  # descending by count\n",
    "cum_counts   = class_counts[sorted_idxs].cumsum()\n",
    "total        = class_counts.sum()\n",
    "\n",
    "# find where cumulative hits 33% and 66% of total examples\n",
    "cut1 = np.searchsorted(cum_counts, total * 0.33)\n",
    "cut2 = np.searchsorted(cum_counts, total * 0.66)\n",
    "\n",
    "high_freq_idxs = sorted_idxs[:cut1]\n",
    "mid_freq_idxs  = sorted_idxs[cut1:cut2]\n",
    "low_freq_idxs  = sorted_idxs[cut2:]\n",
    "\n",
    "# 3) Randomly sample up to K from each bucket\n",
    "# ------------------------------------------------\n",
    "rng = np.random.default_rng(42)\n",
    "K_high, K_mid, K_low = 5, 5, 5\n",
    "\n",
    "sel_high = rng.choice(high_freq_idxs,  size=min(K_high, len(high_freq_idxs)), replace=False)\n",
    "sel_mid  = rng.choice(mid_freq_idxs,   size=min(K_mid,  len(mid_freq_idxs)),  replace=False)\n",
    "sel_low  = rng.choice(low_freq_idxs,   size=min(K_low,  len(low_freq_idxs)),  replace=False)\n",
    "\n",
    "selected_classes = np.concatenate([sel_high, sel_mid, sel_low])\n",
    "\n",
    "# 4) Compute per-class calibration curves\n",
    "# ------------------------------------------------\n",
    "n_bins = 15\n",
    "calib_data = {}\n",
    "\n",
    "for cls in selected_classes:\n",
    "    # binary ground-truth for “is this class?”\n",
    "    y_true_bin = (y_test == cls).astype(int)\n",
    "    # predicted probability for that class\n",
    "    y_prob_cls = probs_test[:, cls]\n",
    "\n",
    "    prob_pred, frac_true = calibration_curve(\n",
    "        y_true_bin,\n",
    "        y_prob_cls,\n",
    "        n_bins=n_bins,\n",
    "        strategy=\"uniform\"\n",
    "    )\n",
    "    calib_data[cls] = (prob_pred, frac_true)\n",
    "\n",
    "# 5) Plot them together\n",
    "# ------------------------------------------------\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot([0, 1], [0, 1], 'k--', label=\"Ideal\")\n",
    "\n",
    "for cls in selected_classes:\n",
    "    prob_pred, frac_true = calib_data[cls]\n",
    "    plt.plot(\n",
    "        prob_pred,\n",
    "        frac_true,\n",
    "        marker='o',\n",
    "        linestyle='-',\n",
    "        label=f\"class {cls} (freq={class_counts[cls]})\"\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Mean predicted probability\")\n",
    "plt.ylabel(\"Fraction of positives\")\n",
    "plt.title(f\"Reliability diagram for {len(selected_classes)} sample classes\")\n",
    "plt.legend(loc=\"lower right\", fontsize=\"small\", ncol=1)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867345b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
