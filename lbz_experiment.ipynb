{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### preprocessing\n",
    "- drop NaN values\n",
    "- removed 3rd gender (n=1)\n",
    "- merge rare classes\n",
    "- drop classes with less than 25 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relative imports\n",
    "from uncertainty_aware_diagnosis import ICD10data, SimpleMLP\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# absolute imports\n",
    "import polars as pl\n",
    "import pickle\n",
    "import numpy as np\n",
    "from pycalib.visualisations import plot_reliability_diagram\n",
    "from pycalib.models.calibrators import LogisticCalibration\n",
    "from pycalib.metrics import classwise_ECE, conf_ECE\n",
    "\n",
    "# paths\n",
    "train_csv = \"./data/lbz-train.csv\"\n",
    "val_csv = \"./data/lbz-val.csv\"\n",
    "test_csv = \"./data/lbz-test.csv\"\n",
    "ohe_pkl = \"./data/ohe_cats.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "target = \"icd10_main_code\"\n",
    "categorical = [\n",
    "    \"zorginstellingnaam\",\n",
    "    \"gender\",\n",
    "    \"clinical_specialty\",\n",
    "    \"DBC_specialty_code\",\n",
    "    \"DBC_diagnosis_code\",\n",
    "    \"icd10_subtraject_code\",\n",
    "]\n",
    "numerical = [\"age\"]\n",
    "\n",
    "# get one-hot encoded features of full dataset (all categories)\n",
    "# ohe_df = pl.read_csv(ohe_csv).to_pandas()['ohe_cats']\n",
    "# ohe_cats =[]\n",
    "# for cat in ohe_df:\n",
    "#     ohe_cats.append(cat)\n",
    "\n",
    "with open(ohe_pkl, \"rb\") as f:\n",
    "    ohe_cats = pickle.load(f)\n",
    "\n",
    "train = ICD10data(\n",
    "    csv_path=train_csv,\n",
    "    numerical=numerical,\n",
    "    categorical=categorical,\n",
    "    high_card=[],\n",
    "    target=target,\n",
    "    dropna=True,\n",
    "    use_embedding=False,\n",
    "    ohe_categories=ohe_cats,  # use one-hot encoded categorie of full dataset\n",
    ")\n",
    "val = ICD10data(\n",
    "    csv_path=val_csv,\n",
    "    numerical=numerical,\n",
    "    categorical=categorical,\n",
    "    high_card=[],\n",
    "    target=target,\n",
    "    dropna=True,\n",
    "    use_embedding=False,\n",
    "    ohe_categories=ohe_cats,  # use one-hot encoded categorie of full dataset\n",
    "    encoder=train.encoder,  # use encoder from training set\n",
    "    scaler=train.scaler,  # use scalor from train set\n",
    ")\n",
    "test = ICD10data(\n",
    "    csv_path=test_csv,\n",
    "    numerical=numerical,\n",
    "    categorical=categorical,\n",
    "    high_card=[],\n",
    "    target=target,\n",
    "    dropna=True,\n",
    "    use_embedding=False,\n",
    "    ohe_categories=ohe_cats,  # use one-hot encoded categorie of full dataset\n",
    "    encoder=train.encoder,  # use encoder from training set\n",
    "    scaler=train.scaler,  # use scalor from train set\n",
    ")\n",
    "\n",
    "input_dim = train.X.shape[1]\n",
    "output_dim = train.classes.shape[0]\n",
    "\n",
    "print(f\"Number of icd10 classes: {len(train.classes)}\")\n",
    "print(f\"(input_dim: {input_dim}, output_dim: {output_dim})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables dataloader\n",
    "batch_size = 32\n",
    "shuffle = True\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=shuffle)\n",
    "val_loader = DataLoader(val, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables MLP\n",
    "num_epochs = 25\n",
    "early_stopping_patience = 10\n",
    "learning_rate = 1e-3\n",
    "dropout = 0.2\n",
    "hidden_dim = 256\n",
    "\n",
    "model = SimpleMLP(\n",
    "    input_dim=input_dim, hidden_dim=hidden_dim, num_classes=output_dim, dropout=dropout\n",
    ")\n",
    "model.fit(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    num_epochs=num_epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    early_stopping_patience=early_stopping_patience,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "y_pred = model.predict(test.X)\n",
    "y_proba = model.predict_proba(test.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test.y.numpy()\n",
    "\n",
    "# select y labels: the most common, the most rare, and middle\n",
    "y_select_table = (\n",
    "    pl.DataFrame(train.y.numpy()).to_series().value_counts(sort=True)[0, 500, -1]\n",
    ")\n",
    "y_select = list(y_select_table[\"column_0\"])\n",
    "y_mask = np.isin(y_test, y_select)\n",
    "y_test_select = y_test[y_mask]\n",
    "y_proba_rows_select = y_proba[y_mask]\n",
    "y_proba_select = y_proba_rows_select[:, y_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_reliability_diagram(\n",
    "    y_test_select,\n",
    "    [\n",
    "        y_proba_select,\n",
    "    ],\n",
    "    legend=[\n",
    "        \"MLP\",\n",
    "    ],\n",
    "    class_names=list(test.classes[y_select]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables calibrator\n",
    "C = 0.002\n",
    "solver = \"lbfgs\"\n",
    "\n",
    "# 1) get your raw logits from the MLP\n",
    "props_val = model.predict_proba(val.X)  # shape (n_val, n_classes)\n",
    "probs_test = model.predict_proba(test.X)  # shape (n_test, n_classes)\n",
    "\n",
    "# 2) instantiate & fit the pycalib logistic (Platt) calibrator\n",
    "calibrator = LogisticCalibration(\n",
    "    C=C, solver=solver, multi_class=\"multinomial\", log_transform=True\n",
    ")\n",
    "calibrator.fit(props_val, val.y.numpy())\n",
    "\n",
    "# 3) use it to get calibrated probabilities on your test set\n",
    "probs_calibrated = calibrator.predict_proba(probs_test)  # shape (n_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba_rows_select_test = probs_test[y_mask]\n",
    "y_proba_select_test = y_proba_rows_select_test[:, y_select]\n",
    "y_proba_rows_select_cali = probs_calibrated[y_mask]\n",
    "y_proba_select_cali = y_proba_rows_select_cali[:, y_select]\n",
    "\n",
    "_ = plot_reliability_diagram(\n",
    "    y_test_select,\n",
    "    [y_proba_select_test, y_proba_select_cali],\n",
    "    legend=[\"MLP\", \"+ Calibrator\"],\n",
    "    class_names=list(test.classes[y_select]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in conf_ECE, classwise_ECE:  # ECE,\n",
    "    print(metric.__name__)\n",
    "    print(\"Classifier = {:.3f}\".format(metric(test.y.numpy(), probs_test, bins=15)))\n",
    "    print(\n",
    "        \"Calibrator = {:.3f}\".format(metric(test.y.numpy(), probs_calibrated, bins=15))\n",
    "    )\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
