{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic data generation for demo purposes\n",
    "- generate an target variable that is hierarchically structured like ICD10, with a large label space and exponential class imbalance\n",
    "- generate features with dependencies to each other and the target variable\n",
    "- generate different class distributions for different hospitals to simulate heterogeneity \n",
    "- corrupt the target label with categorical shift and swapped values to simulate label noise\n",
    "\n",
    "# Standard preprocessing\n",
    "- load data into ICD10data class (for preprocessing)\n",
    "- conduct stratified train, calibrate, test split\n",
    "- export data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate synthetic data\n",
    "\n",
    "(around 30.000 day admissions per year per hospital)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_hospital=150000 # 5 years of data\n",
    "hospital_specializations = ['cardiology', 'neurology', 'oncology', 'academic', 'general'] # 5 different distributions of the target classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthetic_admissions import generate_federated_sources\n",
    "\n",
    "# parameters\n",
    "p=0.6 # proportion of common codes despite hospital specialization (the bigger the less heterogeneity)\n",
    "variance=0.025 # variance of the noise\n",
    "p2=0.5 # power factor for the digits\n",
    "seed=42 # random seed\n",
    "corr = 0.89 # correlation to target\n",
    "corr2 = 0.78 # correlation to target\n",
    "\n",
    "noisy_federated_data = generate_federated_sources(\n",
    "    hospital_specializations=hospital_specializations,\n",
    "    samples_per_hospital=samples_per_hospital,\n",
    "    p=p,\n",
    "    variance=variance,\n",
    "    p2=p2,\n",
    "    corr=corr,\n",
    "    corr2=corr2,\n",
    "    seed=seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate synthetic data from a different distribution for each hospital specialization\n",
    "federated_data_sources = generate_federated_sources(\n",
    "    hospital_specializations=hospital_specializations,\n",
    "    samples_per_hospital=samples_per_hospital,\n",
    "    p=p,\n",
    "    variance=variance,\n",
    "    p2=p2,\n",
    "    seed=seed\n",
    ")\n",
    "federated_data_sources.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv_path = \"./data/synthetic_admission_data.csv\"\n",
    "federated_data_sources.write_csv(export_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corrupt target label to simulate label noise\n",
    "(26 min runtime for 750k rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthetic_admissions import corrupt_target_label\n",
    "\n",
    "# corrupt the target label by swapping 1/5th of the labels and categorical shift (close to the target) by 4/5th \n",
    "noisy_federated_data = corrupt_target_label(federated_data_sources, noise_rate=0.2, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/synthetic_noisy_admission_data.csv\"\n",
    "noisy_federated_data.write_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from uncertainty_aware_diagnosis import ICD10data\n",
    "\n",
    "input_csv =  \"./data/synthetic_noisy_admission_data.csv\" # \"./data/synthetic_admission_data.csv\"\n",
    "\n",
    "# settings for the data_config\n",
    "data_config = {\n",
    "  'target': 'admission_code', # similated but fake ICD10 code\n",
    "  'numerical_features': ['age'],\n",
    "  'categorical_features': ['hospital','gender', 'clinical_specialty', 'billing_diagnosis_code', 'billing_specialty_code', 'subtraject_code'],\n",
    "  'high_cardinality_features': ['procedure_code'],\n",
    "  'use_embedding': False,\n",
    "  'train_csv': \"./data/synthetic_train.csv\",\n",
    "  'val_csv': \"./data/synthetic_val.csv\",\n",
    "  'test_csv': \"./data/synthetic_test.csv\",\n",
    "  'ohe_pkl': \"./data/synthetic_ohe_cats.pkl\"\n",
    "}\n",
    "\n",
    "# store data_config in a python file in the data folder\n",
    "# Ensure the directory exists\n",
    "data_config_path = \"./data/data_config.py\"\n",
    "os.makedirs(os.path.dirname(data_config_path), exist_ok=True)\n",
    "\n",
    "# Write the data_config to a Python file\n",
    "with open(data_config_path, \"w\") as f:\n",
    "    f.write(\"data_config = \")\n",
    "    f.write(repr(data_config))\n",
    "\n",
    "print(f\"data_config stored in {data_config_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ICD10data(\n",
    "    csv_path=input_csv,\n",
    "    numerical=data_config['numerical_features'],\n",
    "    categorical=data_config['categorical_features'],\n",
    "    high_card=[],\n",
    "    target=data_config['target'],\n",
    "    dropna=True,\n",
    "    use_embedding=False,\n",
    ")\n",
    "\n",
    "# save the encoder categories of the complete dataset (to be reused for the train, val, test set)\n",
    "with open('synthetic_ohe_cats.pkl', 'wb') as f:\n",
    "    pickle.dump(data.encoder.categories, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, calibrate, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uncertainty_aware_diagnosis import split_and_save_csv\n",
    "\n",
    "split_and_save_csv(\n",
    "    input_csv=input_csv,\n",
    "    train_csv=data_config['train_csv'],\n",
    "    val_csv=data_config['val_csv'],\n",
    "    test_csv=data_config['test_csv'],\n",
    "    train_frac=0.7,\n",
    "    val_frac=0.15,\n",
    "    test_frac=0.15,\n",
    "    stratify_col=data_config['target'],  # preserve class balance\n",
    "    min_class_count=25,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pl.read_csv(data_config['train_csv'])\n",
    "\n",
    "print(\"Total classes: \", train.get_column(\"admission_code\").n_unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splits sizes: train=522554, val=111976, test=111977 | Total classes:  793"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
